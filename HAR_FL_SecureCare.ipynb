{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVArLbQmHNWj"
      },
      "source": [
        "# **NEURAL NETWORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_NHXboVAA5h",
        "outputId": "27dc434a-4f99-4ad0-85b4-75a605e95089"
      },
      "outputs": [],
      "source": [
        "# Improved Deep Neural Network for HAR Classification\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"SecureCare_Data.csv\")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(['Time', 'Person'], axis=1)\n",
        "\n",
        "# Encode target\n",
        "label_encoder = LabelEncoder()\n",
        "df['Class'] = label_encoder.fit_transform(df['Class'])\n",
        "\n",
        "# Split features and labels\n",
        "X = df.drop('Class', axis=1).values\n",
        "y = df['Class'].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# Build deeper model\n",
        "model = Sequential([\n",
        "    Dense(256, input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(128),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(y_train_cat.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=60,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"üìä Model Performance:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aTOM9w04AA25",
        "outputId": "e09c22d1-ebaf-45b7-ffec-0dd199e15ab6"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# Federated Learning with 5 Clients (FedAvg)\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# -------------------------------\n",
        "# Load and preprocess dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"/content/SecureCare_Data.csv\")\n",
        "df = df.drop(['Time', 'Person'], axis=1)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['Class'] = label_encoder.fit_transform(df['Class'])\n",
        "\n",
        "X = df.drop('Class', axis=1).values\n",
        "y = df['Class'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# -------------------------------\n",
        "# Split data for 5 clients\n",
        "# -------------------------------\n",
        "num_clients = 5\n",
        "client_data = []\n",
        "split_size = len(X_train) // num_clients\n",
        "for i in range(num_clients):\n",
        "    start, end = i * split_size, (i + 1) * split_size\n",
        "    client_data.append((X_train[start:end], y_train_cat[start:end]))\n",
        "\n",
        "# -------------------------------\n",
        "# Build model function\n",
        "# -------------------------------\n",
        "def build_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_shape=(input_dim,)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Dense(128),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(64),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# -------------------------------\n",
        "# FedAvg Aggregation Function\n",
        "# -------------------------------\n",
        "def fedavg(global_model, client_models, client_sizes):\n",
        "    global_weights = []\n",
        "    total_samples = np.sum(client_sizes)\n",
        "\n",
        "    for weights_list_tuple in zip(*[m.get_weights() for m in client_models]):\n",
        "        weighted_sum = np.sum([w * (n / total_samples) for w, n in zip(weights_list_tuple, client_sizes)], axis=0)\n",
        "        global_weights.append(weighted_sum)\n",
        "\n",
        "    global_model.set_weights(global_weights)\n",
        "    return global_model\n",
        "\n",
        "# -------------------------------\n",
        "# Federated Learning Simulation\n",
        "# -------------------------------\n",
        "global_model = build_model(X_train.shape[1], y_train_cat.shape[1])\n",
        "num_rounds = 10\n",
        "local_epochs = 5\n",
        "\n",
        "global_acc, client_acc_history = [], []\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"\\nüåÄ Round {round_num + 1}/{num_rounds}\")\n",
        "    client_models = []\n",
        "    client_sizes = []\n",
        "    round_accuracies = []\n",
        "\n",
        "    for client_id, (X_c, y_c) in enumerate(client_data):\n",
        "        print(f\"  - Training Client {client_id + 1}\")\n",
        "        client_model = clone_model(global_model)\n",
        "        client_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        client_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        client_model.fit(X_c, y_c, epochs=local_epochs, batch_size=64, verbose=0)\n",
        "\n",
        "        acc = client_model.evaluate(X_c, y_c, verbose=0)[1]\n",
        "        round_accuracies.append(acc)\n",
        "        client_models.append(client_model)\n",
        "        client_sizes.append(len(X_c))\n",
        "\n",
        "    # FedAvg aggregation\n",
        "    global_model = fedavg(global_model, client_models, client_sizes)\n",
        "    global_eval = global_model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "    global_acc.append(global_eval[1])\n",
        "    client_acc_history.append(round_accuracies)\n",
        "\n",
        "    print(f\"‚úÖ Global Accuracy after round {round_num + 1}: {global_eval[1]:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Final Evaluation\n",
        "# -------------------------------\n",
        "y_pred = np.argmax(global_model.predict(X_test), axis=1)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nüéØ Final Federated Model Accuracy:\", round(acc, 4))\n",
        "\n",
        "# -------------------------------\n",
        "# Visualization\n",
        "# -------------------------------\n",
        "\n",
        "# 1Ô∏è‚É£ Global Accuracy across rounds\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1, num_rounds+1), global_acc, marker='o')\n",
        "plt.title(\"Global Model Accuracy per Round (FedAvg)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 2Ô∏è‚É£ Client Accuracy trends\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(num_clients):\n",
        "    plt.plot(range(1, num_rounds+1), [accs[i] for accs in client_acc_history], label=f'Client {i+1}')\n",
        "plt.title(\"Client Training Accuracy per Round\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 3Ô∏è‚É£ Comparison with Centralized Model\n",
        "centralized_acc = 0.71  # From your previous model\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.bar(['Centralized', 'Federated'], [centralized_acc, acc], color=['skyblue', 'orange'])\n",
        "plt.title(\"Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "for i, v in enumerate([centralized_acc, acc]):\n",
        "    plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', fontsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guZ_YcxDHSFS"
      },
      "source": [
        "# **ML Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsnoyS69V6f3"
      },
      "source": [
        "**Comparison of ML Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "bxKVbSCnJcHT",
        "outputId": "74e1ecdf-9dfb-4ecd-ceb0-f3e38ece8c4c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load & clean dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"/content/SecureCare_Data.csv\")\n",
        "df = df.drop(['Time', 'Person'], axis=1)\n",
        "\n",
        "# Label encode class names\n",
        "le = LabelEncoder()\n",
        "df['Class'] = le.fit_transform(df['Class'])\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Window-based feature extraction\n",
        "# -------------------------------\n",
        "WINDOW_SIZE = 128\n",
        "STEP_SIZE = 64\n",
        "\n",
        "def extract_features(df, window_size=WINDOW_SIZE, step_size=STEP_SIZE):\n",
        "    feats, labels = [], []\n",
        "    for start in range(0, len(df) - window_size, step_size):\n",
        "        end = start + window_size\n",
        "        window = df.iloc[start:end]\n",
        "        label = window['Class'].mode()[0]\n",
        "        feature_dict = {\n",
        "            'Acc_x_mean': window['Acc_x'].mean(),\n",
        "            'Acc_y_mean': window['Acc_y'].mean(),\n",
        "            'Acc_z_mean': window['Acc_z'].mean(),\n",
        "            'Acc_x_std': window['Acc_x'].std(),\n",
        "            'Acc_y_std': window['Acc_y'].std(),\n",
        "            'Acc_z_std': window['Acc_z'].std(),\n",
        "            'Acc_x_min': window['Acc_x'].min(),\n",
        "            'Acc_y_min': window['Acc_y'].min(),\n",
        "            'Acc_z_min': window['Acc_z'].min(),\n",
        "            'Acc_x_max': window['Acc_x'].max(),\n",
        "            'Acc_y_max': window['Acc_y'].max(),\n",
        "            'Acc_z_max': window['Acc_z'].max(),\n",
        "            'Acc_mag_mean': np.sqrt((window['Acc_x']**2 + window['Acc_y']**2 + window['Acc_z']**2)).mean(),\n",
        "            'Acc_mag_std': np.sqrt((window['Acc_x']**2 + window['Acc_y']**2 + window['Acc_z']**2)).std(),\n",
        "            'Acc_range': window[['Acc_x','Acc_y','Acc_z']].max().mean() - window[['Acc_x','Acc_y','Acc_z']].min().mean(),\n",
        "            'Acc_energy': np.sum(window[['Acc_x','Acc_y','Acc_z']]**2).sum()\n",
        "        }\n",
        "        feats.append(feature_dict)\n",
        "        labels.append(label)\n",
        "    features_df = pd.DataFrame(feats)\n",
        "    features_df['Class'] = labels\n",
        "    return features_df\n",
        "\n",
        "df_feat = extract_features(df)\n",
        "print(\" Features extracted:\", df_feat.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Split dataset\n",
        "# -------------------------------\n",
        "X = df_feat.drop('Class', axis=1)\n",
        "y = df_feat['Class']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_norm = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_norm, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 4. XGBoost hyperparameter tuning\n",
        "# -------------------------------\n",
        "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [200, 400, 600, 800, 1000],\n",
        "    'max_depth': [4, 6, 8, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'reg_lambda': [1, 1.5, 2],\n",
        "    'reg_alpha': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "rand_search = RandomizedSearchCV(\n",
        "    xgb_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=15,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rand_search.fit(X_train, y_train)\n",
        "best_xgb = rand_search.best_estimator_\n",
        "print(\"\\n Best XGBoost Parameters:\", rand_search.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Random Forest model\n",
        "# -------------------------------\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300, max_depth=12, random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Voting Ensemble (XGB + RF)\n",
        "# -------------------------------\n",
        "voting = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', best_xgb),\n",
        "        ('rf', rf_model)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "voting.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Evaluate all models\n",
        "# -------------------------------\n",
        "models = {\n",
        "    \"XGBoost\": best_xgb,\n",
        "    \"Random Forest\": rf_model,\n",
        "    \"Voting Ensemble\": voting\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    rec = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    results.append((name, acc, prec, rec, f1))\n",
        "    print(f\"{name}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Plot performance\n",
        "# -------------------------------\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "results_df = results_df.sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.barh(results_df[\"Model\"], results_df[\"Accuracy\"], color='skyblue')\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title(\"‚öôÔ∏è Model Comparison on SecureCare (Windowed Features)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Final Model Performance Summary:\")\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZ-envVw-1"
      },
      "source": [
        "**Voting Classifier + FL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VKOTp9bBSB0s",
        "outputId": "bed97ab4-1ac2-43bc-bd6f-6c3f45bcbc0a"
      },
      "outputs": [],
      "source": [
        "# ===========================================================\n",
        "# üè• SecureCare HAR ‚Äî Federated Learning (FedAvg Probabilities)\n",
        "# Model: Voting Ensemble (Tuned XGBoost + RandomForest)\n",
        "# Clients: 5 (Stratified splits) | Rounds: 5\n",
        "# ===========================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------------\n",
        "# 1) Load & clean dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"/content/SecureCare_Data.csv\")\n",
        "df = df.drop(['Time', 'Person'], axis=1)\n",
        "\n",
        "# Label encode class names\n",
        "le = LabelEncoder()\n",
        "df['Class'] = le.fit_transform(df['Class'])\n",
        "\n",
        "# -------------------------------\n",
        "# 2) Window-based feature extraction (HAR-style)\n",
        "# -------------------------------\n",
        "WINDOW_SIZE = 128\n",
        "STEP_SIZE   = 64\n",
        "\n",
        "def extract_features(df, window_size=WINDOW_SIZE, step_size=STEP_SIZE):\n",
        "    feats, labels = [], []\n",
        "    for start in range(0, len(df) - window_size, step_size):\n",
        "        end = start + window_size\n",
        "        window = df.iloc[start:end]\n",
        "        label = window['Class'].mode()[0]\n",
        "        # Statistical + magnitude features\n",
        "        ax, ay, az = window['Acc_x'], window['Acc_y'], window['Acc_z']\n",
        "        amag = np.sqrt(ax**2 + ay**2 + az**2)\n",
        "        feature_dict = {\n",
        "            'Acc_x_mean': ax.mean(),   'Acc_y_mean': ay.mean(),   'Acc_z_mean': az.mean(),\n",
        "            'Acc_x_std':  ax.std(),    'Acc_y_std':  ay.std(),    'Acc_z_std':  az.std(),\n",
        "            'Acc_x_min':  ax.min(),    'Acc_y_min':  ay.min(),    'Acc_z_min':  az.min(),\n",
        "            'Acc_x_max':  ax.max(),    'Acc_y_max':  ay.max(),    'Acc_z_max':  az.max(),\n",
        "            'Acc_mag_mean': amag.mean(),\n",
        "            'Acc_mag_std':  amag.std(),\n",
        "            'Acc_range': (pd.DataFrame({'x':ax,'y':ay,'z':az}).max().mean()\n",
        "                         -pd.DataFrame({'x':ax,'y':ay,'z':az}).min().mean()),\n",
        "            'Acc_energy':  (ax**2 + ay**2 + az**2).sum()\n",
        "        }\n",
        "        feats.append(feature_dict)\n",
        "        labels.append(label)\n",
        "    features_df = pd.DataFrame(feats)\n",
        "    features_df['Class'] = labels\n",
        "    return features_df\n",
        "\n",
        "df_feat = extract_features(df)\n",
        "print(\" Features extracted:\", df_feat.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# 3) Train/Test split + normalization\n",
        "# -------------------------------\n",
        "X = df_feat.drop('Class', axis=1)\n",
        "y = df_feat['Class']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "Xn = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    Xn, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "# -------------------------------\n",
        "# 4) Tune XGBoost on global train (same as your best run)\n",
        "# -------------------------------\n",
        "xgb_base = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators':    [200, 400, 600, 800, 1000],\n",
        "    'max_depth':       [4, 6, 8, 10],\n",
        "    'learning_rate':   [0.01, 0.05, 0.1],\n",
        "    'subsample':       [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree':[0.7, 0.8, 1.0],\n",
        "    'min_child_weight':[1, 3, 5],\n",
        "    'gamma':           [0, 0.1, 0.2],\n",
        "    'reg_lambda':      [1, 1.5, 2],\n",
        "    'reg_alpha':       [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    xgb_base, param_distributions=param_dist,\n",
        "    n_iter=15, cv=3, scoring='accuracy', n_jobs=-1, verbose=1, random_state=42\n",
        ")\n",
        "search.fit(X_train, y_train)\n",
        "best_xgb = search.best_estimator_\n",
        "print(\"\\n Best XGBoost Params:\", search.best_params_)\n",
        "\n",
        "# Fixed RF to pair with tuned XGB in the ensemble\n",
        "rf_global = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42)\n",
        "\n",
        "def build_best_voter():\n",
        "    return VotingClassifier(\n",
        "        estimators=[('xgb', best_xgb), ('rf', rf_global)],\n",
        "        voting='soft'\n",
        "    )\n",
        "\n",
        "# -------------------------------\n",
        "# 5) Helper: evaluate metrics\n",
        "# -------------------------------\n",
        "def evaluate(y_true, y_pred):\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='weighted')\n",
        "    rec  = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1   = f1_score(y_true, y_pred, average='weighted')\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "# -------------------------------\n",
        "# 6) Make 5 stratified clients from the TRAIN set\n",
        "# -------------------------------\n",
        "def make_clients(X, y, num_clients=5, seed=42):\n",
        "    skf = StratifiedKFold(n_splits=num_clients, shuffle=True, random_state=seed)\n",
        "    splits = []\n",
        "    for _, idx in skf.split(X, y):\n",
        "        splits.append(idx)\n",
        "    clients = []\n",
        "    for idx in splits:\n",
        "        clients.append((X[idx], y.iloc[idx].values))\n",
        "    return clients\n",
        "\n",
        "clients = make_clients(X_train, y_train, num_clients=5, seed=42)\n",
        "for i, (Xc, yc) in enumerate(clients, 1):\n",
        "    print(f\" Client {i}: {len(yc)} samples\")\n",
        "\n",
        "# -------------------------------\n",
        "# 7) Federated training (FedAvg on probabilities)\n",
        "# -------------------------------\n",
        "ROUNDS = 30\n",
        "global_metrics = []\n",
        "round_client_metrics = []  # list of dicts per round\n",
        "\n",
        "for r in range(1, ROUNDS+1):\n",
        "    print(f\"\\n Federated Round {r}/{ROUNDS}\")\n",
        "    client_probs = []     # predicted probabilities on global test, per client\n",
        "    client_weights = []   # weight by client size\n",
        "    client_stats = []     # local metrics on client-held-out validation (optional quick split)\n",
        "\n",
        "    # Train each client locally on its partition\n",
        "    for ci, (Xc, yc) in enumerate(clients, 1):\n",
        "        # simple local validation split (10%) to report client-side metrics (no leakage)\n",
        "        msk = np.random.RandomState(1000 + r + ci).rand(len(yc)) < 0.9\n",
        "        Xc_tr, yc_tr = Xc[msk], yc[msk]\n",
        "        Xc_va, yc_va = Xc[~msk], yc[~msk]\n",
        "\n",
        "        model = build_best_voter()\n",
        "        model.fit(Xc_tr, yc_tr)\n",
        "\n",
        "        # metrics on client's local holdout\n",
        "        if len(yc_va) > 0:\n",
        "            yva_pred = model.predict(Xc_va)\n",
        "            cacc, cprec, crec, cf1 = evaluate(yc_va, yva_pred)\n",
        "        else:\n",
        "            cacc = cprec = crec = cf1 = np.nan\n",
        "\n",
        "        client_stats.append({\n",
        "            \"client\": ci,\n",
        "            \"n_train\": len(yc_tr),\n",
        "            \"n_val\": len(yc_va),\n",
        "            \"acc\": cacc, \"prec\": cprec, \"rec\": crec, \"f1\": cf1\n",
        "        })\n",
        "\n",
        "        # store probs on the shared global test set for FedAvg\n",
        "        p_test = model.predict_proba(X_test)  # shape: [n_test, n_classes]\n",
        "        client_probs.append(p_test)\n",
        "        client_weights.append(len(yc_tr))  # size-weighted FedAvg\n",
        "\n",
        "    # FedAvg on probabilities (size-weighted)\n",
        "    client_weights = np.array(client_weights, dtype=float)\n",
        "    client_weights = client_weights / client_weights.sum()\n",
        "    P = np.zeros_like(client_probs[0])\n",
        "    for w, P_i in zip(client_weights, client_probs):\n",
        "        P += w * P_i\n",
        "\n",
        "    y_pred_global = np.argmax(P, axis=1)\n",
        "    acc, prec, rec, f1 = evaluate(y_test, y_pred_global)\n",
        "    global_metrics.append((acc, prec, rec, f1))\n",
        "    round_client_metrics.append(client_stats)\n",
        "\n",
        "    print(f\" Global after Round {r}: \"\n",
        "          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | F1={f1:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8) Plot global metrics per round\n",
        "# -------------------------------\n",
        "gm = np.array(global_metrics)\n",
        "r = np.arange(1, ROUNDS+1)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(r, gm[:,0], marker='o', label='Accuracy')\n",
        "plt.plot(r, gm[:,1], marker='o', label='Precision (weighted)')\n",
        "plt.plot(r, gm[:,2], marker='o', label='Recall (weighted)')\n",
        "plt.plot(r, gm[:,3], marker='o', label='F1 (weighted)')\n",
        "plt.xlabel(\"Federated Round\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Global Performance per Federated Round (Voting Ensemble)\")\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 9) Final confusion matrix (last round)\n",
        "# -------------------------------\n",
        "cm = confusion_matrix(y_test, y_pred_global, labels=np.arange(n_classes))\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title(\"Confusion Matrix (Global Model, Final Round)\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(n_classes)\n",
        "plt.xticks(tick_marks, le.inverse_transform(np.arange(n_classes)), rotation=45, ha='right')\n",
        "plt.yticks(tick_marks, le.inverse_transform(np.arange(n_classes)))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "# annotate counts\n",
        "thresh = cm.max() / 2.0\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 10) Print per-client stats (last round)\n",
        "# -------------------------------\n",
        "print(\"\\n Per-Client Metrics (last round local holdout):\")\n",
        "for s in round_client_metrics[-1]:\n",
        "    print(f\"Client {s['client']}: n_train={s['n_train']}, n_val={s['n_val']}, \"\n",
        "          f\"acc={s['acc']:.4f}, prec={s['prec']:.4f}, rec={s['rec']:.4f}, f1={s['f1']:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 11) Print global summary\n",
        "# -------------------------------\n",
        "print(\"\\n Global Metrics per Round (Acc, Prec, Rec, F1):\")\n",
        "for i, m in enumerate(global_metrics, 1):\n",
        "    print(f\"Round {i}: Acc={m[0]:.4f}, Prec={m[1]:.4f}, Rec={m[2]:.4f}, F1={m[3]:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
